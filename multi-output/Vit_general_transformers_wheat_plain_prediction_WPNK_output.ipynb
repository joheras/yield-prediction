{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "import fastai\n",
    "import timm\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/wheat_new.csv',decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'vit_base_patch16_384'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file</th>\n",
       "      <th>DAS</th>\n",
       "      <th>plot nº</th>\n",
       "      <th>photo nº</th>\n",
       "      <th>species</th>\n",
       "      <th>water_treatment</th>\n",
       "      <th>management</th>\n",
       "      <th>plot m2</th>\n",
       "      <th>avg_water (L m-2)</th>\n",
       "      <th>...</th>\n",
       "      <th>P (kg microplot-1)</th>\n",
       "      <th>K (kg microplot-1)</th>\n",
       "      <th>avg_height</th>\n",
       "      <th>GA</th>\n",
       "      <th>GGA</th>\n",
       "      <th>CSI</th>\n",
       "      <th>NGRDIveg</th>\n",
       "      <th>TGIveg</th>\n",
       "      <th>final yield (kg)</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20220517_1 (1).JPG</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>(1).</td>\n",
       "      <td>wheat</td>\n",
       "      <td>ww</td>\n",
       "      <td>conv</td>\n",
       "      <td>12</td>\n",
       "      <td>3096.2375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.072</td>\n",
       "      <td>46.9715</td>\n",
       "      <td>0.959407</td>\n",
       "      <td>0.904393</td>\n",
       "      <td>5.734098</td>\n",
       "      <td>0.1324</td>\n",
       "      <td>2569.2709</td>\n",
       "      <td>9.15</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20220517_1 (2).JPG</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>(2).</td>\n",
       "      <td>wheat</td>\n",
       "      <td>ww</td>\n",
       "      <td>conv</td>\n",
       "      <td>12</td>\n",
       "      <td>3096.2375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.072</td>\n",
       "      <td>46.9715</td>\n",
       "      <td>0.963030</td>\n",
       "      <td>0.905523</td>\n",
       "      <td>5.971505</td>\n",
       "      <td>0.1316</td>\n",
       "      <td>2648.0105</td>\n",
       "      <td>9.15</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20220517_1 (3).JPG</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>(3).</td>\n",
       "      <td>wheat</td>\n",
       "      <td>ww</td>\n",
       "      <td>conv</td>\n",
       "      <td>12</td>\n",
       "      <td>3096.2375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.072</td>\n",
       "      <td>46.9715</td>\n",
       "      <td>0.953708</td>\n",
       "      <td>0.898722</td>\n",
       "      <td>5.765430</td>\n",
       "      <td>0.1331</td>\n",
       "      <td>2736.4337</td>\n",
       "      <td>9.15</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20220517_1 (4).JPG</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>(4).</td>\n",
       "      <td>wheat</td>\n",
       "      <td>ww</td>\n",
       "      <td>conv</td>\n",
       "      <td>12</td>\n",
       "      <td>3096.2375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.072</td>\n",
       "      <td>46.9715</td>\n",
       "      <td>0.957117</td>\n",
       "      <td>0.898772</td>\n",
       "      <td>6.095965</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>2550.8238</td>\n",
       "      <td>9.15</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20220602_1 (1).JPG</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>(1).</td>\n",
       "      <td>wheat</td>\n",
       "      <td>ww</td>\n",
       "      <td>conv</td>\n",
       "      <td>12</td>\n",
       "      <td>3096.2375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.072</td>\n",
       "      <td>46.9715</td>\n",
       "      <td>0.892348</td>\n",
       "      <td>0.791199</td>\n",
       "      <td>11.335180</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>1880.2128</td>\n",
       "      <td>9.15</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>251</td>\n",
       "      <td>20220615_25 (4).JPG</td>\n",
       "      <td>125</td>\n",
       "      <td>25</td>\n",
       "      <td>(4).</td>\n",
       "      <td>wheat</td>\n",
       "      <td>d</td>\n",
       "      <td>conv</td>\n",
       "      <td>12</td>\n",
       "      <td>2752.8000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.072</td>\n",
       "      <td>55.2110</td>\n",
       "      <td>0.788544</td>\n",
       "      <td>0.323428</td>\n",
       "      <td>58.984136</td>\n",
       "      <td>0.0491</td>\n",
       "      <td>2277.6824</td>\n",
       "      <td>7.95</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>252</td>\n",
       "      <td>20220701_25 (1).JPG</td>\n",
       "      <td>141</td>\n",
       "      <td>25</td>\n",
       "      <td>(1).</td>\n",
       "      <td>wheat</td>\n",
       "      <td>d</td>\n",
       "      <td>conv</td>\n",
       "      <td>12</td>\n",
       "      <td>2752.8000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.072</td>\n",
       "      <td>55.2110</td>\n",
       "      <td>0.031868</td>\n",
       "      <td>0.009072</td>\n",
       "      <td>71.532905</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>946.1760</td>\n",
       "      <td>7.95</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>253</td>\n",
       "      <td>20220701_25 (2).JPG</td>\n",
       "      <td>141</td>\n",
       "      <td>25</td>\n",
       "      <td>(2).</td>\n",
       "      <td>wheat</td>\n",
       "      <td>d</td>\n",
       "      <td>conv</td>\n",
       "      <td>12</td>\n",
       "      <td>2752.8000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.072</td>\n",
       "      <td>55.2110</td>\n",
       "      <td>0.025828</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>73.483356</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>867.4491</td>\n",
       "      <td>7.95</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>254</td>\n",
       "      <td>20220701_25 (3).JPG</td>\n",
       "      <td>141</td>\n",
       "      <td>25</td>\n",
       "      <td>(3).</td>\n",
       "      <td>wheat</td>\n",
       "      <td>d</td>\n",
       "      <td>conv</td>\n",
       "      <td>12</td>\n",
       "      <td>2752.8000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.072</td>\n",
       "      <td>55.2110</td>\n",
       "      <td>0.022065</td>\n",
       "      <td>0.004773</td>\n",
       "      <td>78.367629</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>855.3556</td>\n",
       "      <td>7.95</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>255</td>\n",
       "      <td>20220701_25 (4).JPG</td>\n",
       "      <td>141</td>\n",
       "      <td>25</td>\n",
       "      <td>(4).</td>\n",
       "      <td>wheat</td>\n",
       "      <td>d</td>\n",
       "      <td>conv</td>\n",
       "      <td>12</td>\n",
       "      <td>2752.8000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.072</td>\n",
       "      <td>55.2110</td>\n",
       "      <td>0.026765</td>\n",
       "      <td>0.007124</td>\n",
       "      <td>73.384338</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>979.4368</td>\n",
       "      <td>7.95</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                 file  DAS  plot nº photo nº species  \\\n",
       "0             0   20220517_1 (1).JPG   96        1     (1).   wheat   \n",
       "1             1   20220517_1 (2).JPG   96        1     (2).   wheat   \n",
       "2             2   20220517_1 (3).JPG   96        1     (3).   wheat   \n",
       "3             3   20220517_1 (4).JPG   96        1     (4).   wheat   \n",
       "4             4   20220602_1 (1).JPG  112        1     (1).   wheat   \n",
       "..          ...                  ...  ...      ...      ...     ...   \n",
       "251         251  20220615_25 (4).JPG  125       25     (4).   wheat   \n",
       "252         252  20220701_25 (1).JPG  141       25     (1).   wheat   \n",
       "253         253  20220701_25 (2).JPG  141       25     (2).   wheat   \n",
       "254         254  20220701_25 (3).JPG  141       25     (3).   wheat   \n",
       "255         255  20220701_25 (4).JPG  141       25     (4).   wheat   \n",
       "\n",
       "    water_treatment management  plot m2  avg_water (L m-2)  ...  \\\n",
       "0                ww       conv       12          3096.2375  ...   \n",
       "1                ww       conv       12          3096.2375  ...   \n",
       "2                ww       conv       12          3096.2375  ...   \n",
       "3                ww       conv       12          3096.2375  ...   \n",
       "4                ww       conv       12          3096.2375  ...   \n",
       "..              ...        ...      ...                ...  ...   \n",
       "251               d       conv       12          2752.8000  ...   \n",
       "252               d       conv       12          2752.8000  ...   \n",
       "253               d       conv       12          2752.8000  ...   \n",
       "254               d       conv       12          2752.8000  ...   \n",
       "255               d       conv       12          2752.8000  ...   \n",
       "\n",
       "     P (kg microplot-1)  K (kg microplot-1)  avg_height        GA       GGA  \\\n",
       "0                 0.072               0.072     46.9715  0.959407  0.904393   \n",
       "1                 0.072               0.072     46.9715  0.963030  0.905523   \n",
       "2                 0.072               0.072     46.9715  0.953708  0.898722   \n",
       "3                 0.072               0.072     46.9715  0.957117  0.898772   \n",
       "4                 0.072               0.072     46.9715  0.892348  0.791199   \n",
       "..                  ...                 ...         ...       ...       ...   \n",
       "251               0.072               0.072     55.2110  0.788544  0.323428   \n",
       "252               0.072               0.072     55.2110  0.031868  0.009072   \n",
       "253               0.072               0.072     55.2110  0.025828  0.006849   \n",
       "254               0.072               0.072     55.2110  0.022065  0.004773   \n",
       "255               0.072               0.072     55.2110  0.026765  0.007124   \n",
       "\n",
       "           CSI  NGRDIveg     TGIveg  final yield (kg)  dataset  \n",
       "0     5.734098    0.1324  2569.2709              9.15    train  \n",
       "1     5.971505    0.1316  2648.0105              9.15    train  \n",
       "2     5.765430    0.1331  2736.4337              9.15    train  \n",
       "3     6.095965    0.1267  2550.8238              9.15    train  \n",
       "4    11.335180    0.1008  1880.2128              9.15    train  \n",
       "..         ...       ...        ...               ...      ...  \n",
       "251  58.984136    0.0491  2277.6824              7.95     test  \n",
       "252  71.532905    0.0342   946.1760              7.95     test  \n",
       "253  73.483356    0.0314   867.4491              7.95     test  \n",
       "254  78.367629    0.0196   855.3556              7.95     test  \n",
       "255  73.384338    0.0265   979.4368              7.95     test  \n",
       "\n",
       "[256 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'file', 'DAS', 'plot nº', 'photo nº', 'species',\n",
       "       'water_treatment', 'management', 'plot m2', 'avg_water (L m-2)',\n",
       "       'N (kg microplot-1)', 'P (kg microplot-1)', 'K (kg microplot-1)',\n",
       "       'avg_height', 'GA', 'GGA', 'CSI', 'NGRDIveg', 'TGIveg',\n",
       "       'final yield (kg)', 'dataset'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = df[(df.dataset=='train')]\n",
    "# dftrain.loc[:,['plot m2', 'avg_water (L m-2)',\n",
    "#        'N (kg microplot-1)', 'P (kg microplot-1)', 'K (kg microplot-1)',\n",
    "#        'avg_height', 'GA', 'GGA', 'CSI', 'NGRDIveg', 'TGIveg',\n",
    "#        'final yield (kg)']] = scaler.fit_transform(dftrain[['plot m2', 'avg_water (L m-2)',\n",
    "#        'N (kg microplot-1)', 'P (kg microplot-1)', 'K (kg microplot-1)',\n",
    "#        'avg_height', 'GA', 'GGA', 'CSI', 'NGRDIveg', 'TGIveg',\n",
    "#        'final yield (kg)']])\n",
    "dfvalid = df[(df.dataset=='validation')]\n",
    "dftest = df[(df.dataset=='test')]\n",
    "# dfvalid.loc[:,['plot m2', 'avg_water (L m-2)',\n",
    "#        'N (kg microplot-1)', 'P (kg microplot-1)', 'K (kg microplot-1)',\n",
    "#        'avg_height', 'GA', 'GGA', 'CSI', 'NGRDIveg', 'TGIveg',\n",
    "#        'final yield (kg)']] = scaler.transform(dfvalid[['plot m2', 'avg_water (L m-2)',\n",
    "#        'N (kg microplot-1)', 'P (kg microplot-1)', 'K (kg microplot-1)',\n",
    "#        'avg_height', 'GA', 'GGA', 'CSI', 'NGRDIveg', 'TGIveg',\n",
    "#        'final yield (kg)']])        \n",
    "# dftest.loc[:,['plot m2', 'avg_water (L m-2)',\n",
    "#        'N (kg microplot-1)', 'P (kg microplot-1)', 'K (kg microplot-1)',\n",
    "#        'avg_height', 'GA', 'GGA', 'CSI', 'NGRDIveg', 'TGIveg',\n",
    "#        'final yield (kg)']] = scaler.transform(dftest[['plot m2', 'avg_water (L m-2)',\n",
    "#        'N (kg microplot-1)', 'P (kg microplot-1)', 'K (kg microplot-1)',\n",
    "#        'avg_height', 'GA', 'GGA', 'CSI', 'NGRDIveg', 'TGIveg',\n",
    "#        'final yield (kg)']])                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = pd.concat([dftrain,dfvalid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([dftrain,dftest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain.loc[:,'dataset'] =  dftrain['dataset'].apply(lambda x: x=='validation')\n",
    "df.loc[:,'dataset'] =  df['dataset'].apply(lambda x: x=='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dftrain.loc[:,'final yield (kg)'] = dftrain['final yield (kg)'].apply(lambda x : (x - 0.8579)/(10.55-0.8579))\n",
    "# df.loc[:,'final yield (kg)'] = df['final yield (kg)'].apply(lambda x : (x - 0.8579)/(10.55-0.8579))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "callbacks = [\n",
    "    ShowGraphCallback(),\n",
    "    # EarlyStoppingCallback(patience=5),\n",
    "    SaveModelCallback(fname=name+'_WPNK_new'), #convnext_yield_all_minmax\n",
    "    # ReduceLROnPlateau()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.metrics import mae,rmse,mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DataBlock(blocks = (ImageBlock,\n",
    "                         RegressionBlock(),RegressionBlock(),RegressionBlock(),RegressionBlock(),\n",
    "                         RegressionBlock(),RegressionBlock(),RegressionBlock()),\n",
    "                 get_x=[ColReader('file',pref='wheat_all/'),\n",
    "                    \n",
    "                        ],\n",
    "                 get_y=[#ColReader('species'),\n",
    "                        #ColReader('water_treatment'),\n",
    "                        #ColReader('management'),\n",
    "                        ColReader('plot m2'),\n",
    "                        ColReader('avg_height'),\n",
    "                        ColReader('avg_water (L m-2)'),\n",
    "                        ColReader('N (kg microplot-1)'),\n",
    "                        ColReader('P (kg microplot-1)'),\n",
    "                        ColReader('K (kg microplot-1)'),\n",
    "                        ColReader('final yield (kg)')],\n",
    "                        # ColReader('GA'),\n",
    "                        # ColReader('GGA'),\n",
    "                        # ColReader('CSI'),\n",
    "                        # ColReader('NGRDIveg'),\n",
    "                        # ColReader('TGIveg')\n",
    "                 splitter=ColSplitter(col='dataset'),    \n",
    "                 item_tfms = Resize(512),\n",
    "                 batch_tfms=[*aug_transforms(size=384,flip_vert=True,\n",
    "                                            max_zoom=1.0), Normalize.from_stats(*imagenet_stats)],\n",
    "               n_inp=1)\n",
    "dls = db.dataloaders(dftrain,bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiInputModel(Module):\n",
    "  \"A three-headed model given a `body` and `n` output features\"\n",
    "  def __init__(self, body:nn.Sequential):\n",
    "    nf = 1\n",
    "    self.body = body\n",
    "    #self.water_treatment = create_head(nf, 4)\n",
    "    #self.management = create_head(nf, 2)\n",
    "    self.avg_water = create_head(nf,1)\n",
    "    self.n = create_head(nf,1)\n",
    "    self.p = create_head(nf,1)\n",
    "    self.k = create_head(nf,1)\n",
    "    self.avg_height = create_head(nf,1)\n",
    "    self.ga = create_head(nf,1)\n",
    "    self.gga = create_head(nf,1)\n",
    "    self.csi = create_head(nf,1)\n",
    "    self.NGRDIveg = create_head(nf,1)\n",
    "    self.TGIveg = create_head(nf,1)\n",
    "    self.yieldprod = create_head(nf,1)\n",
    "\n",
    "    \n",
    "    \n",
    "  \n",
    "  def forward(self, x):\n",
    "    y = self.body(x)\n",
    "    return [\n",
    "        #self.water_treatment(y),\n",
    "        #self.management(y),\n",
    "        self.avg_water(y),\n",
    "        self.n(y),\n",
    "        self.p(y),\n",
    "        self.k(y),\n",
    "        self.avg_height(y),\n",
    "        self.ga(y),\n",
    "        self.gga(y),\n",
    "        self.csi(y),\n",
    "        self.NGRDIveg(y),\n",
    "        self.TGIveg(y),\n",
    "        self.yieldprod(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(name,num_classes=1,pretrained=True)\n",
    "body = nn.Sequential(*list(model.children())[:-1])\n",
    "net = MultiInputModel(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinationLoss(Module):\n",
    "    \"Cross Entropy Loss on multiple targets\"\n",
    "    def __init__(self, func1=F.cross_entropy,func2=F.mse_loss, weights=[2, 1]):\n",
    "        self.func1, self.func2, self.w = func2, func2, weights\n",
    "\n",
    "    def forward(self, xs, *ys, reduction='mean'):\n",
    "        res = self.func2(ys[0],torch.reshape(xs[0],(4,1)))\n",
    "        for i in range(1,6):\n",
    "            res = res + self.func2(ys[i],torch.reshape(xs[i],(4,1)))\n",
    "        res = res + self.func2(ys[6],torch.reshape(xs[6],(4,1)))\n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, net, loss_func=CombinationLoss(),cbs=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8175579.000000</td>\n",
       "      <td>9425953.000000</td>\n",
       "      <td>00:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8160263.500000</td>\n",
       "      <td>9425058.000000</td>\n",
       "      <td>00:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8161755.000000</td>\n",
       "      <td>9432526.000000</td>\n",
       "      <td>00:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8165264.000000</td>\n",
       "      <td>9412970.000000</td>\n",
       "      <td>00:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8162112.000000</td>\n",
       "      <td>9428739.000000</td>\n",
       "      <td>00:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>8153750.000000</td>\n",
       "      <td>9420894.000000</td>\n",
       "      <td>00:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>8141569.500000</td>\n",
       "      <td>9409310.000000</td>\n",
       "      <td>00:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8138344.000000</td>\n",
       "      <td>9419209.000000</td>\n",
       "      <td>00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8135990.500000</td>\n",
       "      <td>9419751.000000</td>\n",
       "      <td>00:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>8149208.500000</td>\n",
       "      <td>9400358.000000</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>8138881.000000</td>\n",
       "      <td>9381108.000000</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>8117894.500000</td>\n",
       "      <td>9370378.000000</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>8087973.500000</td>\n",
       "      <td>9326575.000000</td>\n",
       "      <td>00:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>8063715.000000</td>\n",
       "      <td>9254559.000000</td>\n",
       "      <td>00:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>8019955.500000</td>\n",
       "      <td>9282777.000000</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>7976954.500000</td>\n",
       "      <td>9144898.000000</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>7935261.500000</td>\n",
       "      <td>9099370.000000</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>7868340.000000</td>\n",
       "      <td>9126965.000000</td>\n",
       "      <td>00:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>7793780.000000</td>\n",
       "      <td>8969345.000000</td>\n",
       "      <td>00:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>7710631.500000</td>\n",
       "      <td>8860738.000000</td>\n",
       "      <td>00:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>7656391.500000</td>\n",
       "      <td>8778774.000000</td>\n",
       "      <td>00:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>7556083.500000</td>\n",
       "      <td>8732581.000000</td>\n",
       "      <td>00:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>7467273.000000</td>\n",
       "      <td>8464082.000000</td>\n",
       "      <td>00:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>7384310.500000</td>\n",
       "      <td>8539785.000000</td>\n",
       "      <td>00:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>7290863.500000</td>\n",
       "      <td>8366291.000000</td>\n",
       "      <td>00:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>7203583.500000</td>\n",
       "      <td>8256819.500000</td>\n",
       "      <td>00:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>7119842.500000</td>\n",
       "      <td>8203800.000000</td>\n",
       "      <td>00:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>7014876.500000</td>\n",
       "      <td>8080504.500000</td>\n",
       "      <td>00:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>6935783.000000</td>\n",
       "      <td>7989408.500000</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>6840473.500000</td>\n",
       "      <td>7929314.500000</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>6769702.500000</td>\n",
       "      <td>7808909.500000</td>\n",
       "      <td>00:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>6695552.000000</td>\n",
       "      <td>7735225.000000</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>6631526.500000</td>\n",
       "      <td>7668712.500000</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>6565575.500000</td>\n",
       "      <td>7603632.000000</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>6499458.500000</td>\n",
       "      <td>7546879.000000</td>\n",
       "      <td>00:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>6433358.500000</td>\n",
       "      <td>7466423.000000</td>\n",
       "      <td>00:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>6397515.500000</td>\n",
       "      <td>7447158.000000</td>\n",
       "      <td>00:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>6355475.500000</td>\n",
       "      <td>7395393.500000</td>\n",
       "      <td>00:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>6325136.000000</td>\n",
       "      <td>7370595.500000</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>6288670.000000</td>\n",
       "      <td>7342547.500000</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>6244356.500000</td>\n",
       "      <td>7306374.500000</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>6227300.000000</td>\n",
       "      <td>7296865.000000</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>6206914.000000</td>\n",
       "      <td>7289578.500000</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>6186907.000000</td>\n",
       "      <td>7259361.500000</td>\n",
       "      <td>00:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>6177510.000000</td>\n",
       "      <td>7255828.500000</td>\n",
       "      <td>00:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>6172031.500000</td>\n",
       "      <td>7248226.000000</td>\n",
       "      <td>00:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>6154745.500000</td>\n",
       "      <td>7238255.000000</td>\n",
       "      <td>00:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>6156944.000000</td>\n",
       "      <td>7248684.000000</td>\n",
       "      <td>00:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>6166865.500000</td>\n",
       "      <td>7230205.500000</td>\n",
       "      <td>00:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>6176793.500000</td>\n",
       "      <td>7232429.500000</td>\n",
       "      <td>00:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1554054/3279080324.py:7: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  res = self.func2(ys[0],torch.reshape(xs[0],(4,1)))\n",
      "/tmp/ipykernel_1554054/3279080324.py:9: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  res = res + self.func2(ys[i],torch.reshape(xs[i],(4,1)))\n",
      "/tmp/ipykernel_1554054/3279080324.py:10: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  res = res + self.func2(ys[6],torch.reshape(xs[6],(4,1)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 9425953.0.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 1 with valid_loss value: 9425058.0.\n",
      "Better model found at epoch 3 with valid_loss value: 9412970.0.\n",
      "Better model found at epoch 6 with valid_loss value: 9409310.0.\n",
      "Better model found at epoch 9 with valid_loss value: 9400358.0.\n",
      "Better model found at epoch 10 with valid_loss value: 9381108.0.\n",
      "Better model found at epoch 11 with valid_loss value: 9370378.0.\n",
      "Better model found at epoch 12 with valid_loss value: 9326575.0.\n",
      "Better model found at epoch 13 with valid_loss value: 9254559.0.\n",
      "Better model found at epoch 15 with valid_loss value: 9144898.0.\n",
      "Better model found at epoch 16 with valid_loss value: 9099370.0.\n",
      "Better model found at epoch 18 with valid_loss value: 8969345.0.\n",
      "Better model found at epoch 19 with valid_loss value: 8860738.0.\n",
      "Better model found at epoch 20 with valid_loss value: 8778774.0.\n",
      "Better model found at epoch 21 with valid_loss value: 8732581.0.\n",
      "Better model found at epoch 22 with valid_loss value: 8464082.0.\n",
      "Better model found at epoch 24 with valid_loss value: 8366291.0.\n",
      "Better model found at epoch 25 with valid_loss value: 8256819.5.\n",
      "Better model found at epoch 26 with valid_loss value: 8203800.0.\n",
      "Better model found at epoch 27 with valid_loss value: 8080504.5.\n",
      "Better model found at epoch 28 with valid_loss value: 7989408.5.\n",
      "Better model found at epoch 29 with valid_loss value: 7929314.5.\n",
      "Better model found at epoch 30 with valid_loss value: 7808909.5.\n",
      "Better model found at epoch 31 with valid_loss value: 7735225.0.\n",
      "Better model found at epoch 32 with valid_loss value: 7668712.5.\n",
      "Better model found at epoch 33 with valid_loss value: 7603632.0.\n",
      "Better model found at epoch 34 with valid_loss value: 7546879.0.\n",
      "Better model found at epoch 35 with valid_loss value: 7466423.0.\n",
      "Better model found at epoch 36 with valid_loss value: 7447158.0.\n",
      "Better model found at epoch 37 with valid_loss value: 7395393.5.\n",
      "Better model found at epoch 38 with valid_loss value: 7370595.5.\n",
      "Better model found at epoch 39 with valid_loss value: 7342547.5.\n",
      "Better model found at epoch 40 with valid_loss value: 7306374.5.\n",
      "Better model found at epoch 41 with valid_loss value: 7296865.0.\n",
      "Better model found at epoch 42 with valid_loss value: 7289578.5.\n",
      "Better model found at epoch 43 with valid_loss value: 7259361.5.\n",
      "Better model found at epoch 44 with valid_loss value: 7255828.5.\n",
      "Better model found at epoch 45 with valid_loss value: 7248226.0.\n",
      "Better model found at epoch 46 with valid_loss value: 7238255.0.\n",
      "Better model found at epoch 48 with valid_loss value: 7230205.5.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(50,lr_max=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6165921.000000</td>\n",
       "      <td>7239606.000000</td>\n",
       "      <td>00:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6160634.000000</td>\n",
       "      <td>7232471.000000</td>\n",
       "      <td>00:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6165088.500000</td>\n",
       "      <td>7236671.000000</td>\n",
       "      <td>00:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6163534.000000</td>\n",
       "      <td>7238523.000000</td>\n",
       "      <td>00:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6148673.000000</td>\n",
       "      <td>7229250.000000</td>\n",
       "      <td>00:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6153622.000000</td>\n",
       "      <td>7222905.500000</td>\n",
       "      <td>00:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6147132.000000</td>\n",
       "      <td>7219139.000000</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>6134754.500000</td>\n",
       "      <td>7192810.000000</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6127002.500000</td>\n",
       "      <td>7185082.000000</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>6122089.000000</td>\n",
       "      <td>7172340.500000</td>\n",
       "      <td>00:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6106560.000000</td>\n",
       "      <td>7155692.500000</td>\n",
       "      <td>00:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>6087427.000000</td>\n",
       "      <td>7158375.000000</td>\n",
       "      <td>00:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>6064365.500000</td>\n",
       "      <td>7154866.500000</td>\n",
       "      <td>00:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>6051929.500000</td>\n",
       "      <td>7119400.500000</td>\n",
       "      <td>00:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>6040598.500000</td>\n",
       "      <td>7103815.500000</td>\n",
       "      <td>00:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>6029162.000000</td>\n",
       "      <td>7083582.500000</td>\n",
       "      <td>00:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>6001798.000000</td>\n",
       "      <td>7056889.000000</td>\n",
       "      <td>00:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>6004673.000000</td>\n",
       "      <td>7044088.000000</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>6004756.000000</td>\n",
       "      <td>7020479.000000</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>5963313.000000</td>\n",
       "      <td>7011983.000000</td>\n",
       "      <td>00:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5944159.000000</td>\n",
       "      <td>6999818.000000</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>5932207.500000</td>\n",
       "      <td>6987280.500000</td>\n",
       "      <td>00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>5904077.500000</td>\n",
       "      <td>6952589.500000</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>5891969.500000</td>\n",
       "      <td>6945623.500000</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>5897564.500000</td>\n",
       "      <td>6943307.000000</td>\n",
       "      <td>00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>5887042.500000</td>\n",
       "      <td>6915576.000000</td>\n",
       "      <td>00:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>5867506.000000</td>\n",
       "      <td>6905672.000000</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>5834493.500000</td>\n",
       "      <td>6904635.000000</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>5835291.500000</td>\n",
       "      <td>6895794.000000</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>5827294.500000</td>\n",
       "      <td>6867685.500000</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5831442.500000</td>\n",
       "      <td>6879683.000000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>5830061.500000</td>\n",
       "      <td>6868292.000000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>5818579.500000</td>\n",
       "      <td>6841894.500000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>5801900.500000</td>\n",
       "      <td>6852581.000000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>5785663.000000</td>\n",
       "      <td>6844555.500000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>5772714.000000</td>\n",
       "      <td>6832430.500000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>5780925.000000</td>\n",
       "      <td>6837587.000000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>5759972.000000</td>\n",
       "      <td>6828253.000000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>5775767.500000</td>\n",
       "      <td>6824210.500000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>5770435.000000</td>\n",
       "      <td>6820759.000000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5772582.500000</td>\n",
       "      <td>6812674.000000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>5777435.500000</td>\n",
       "      <td>6814459.500000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>5751719.500000</td>\n",
       "      <td>6808751.500000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>5747943.500000</td>\n",
       "      <td>6793389.500000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>5758853.500000</td>\n",
       "      <td>6813464.500000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>5766620.500000</td>\n",
       "      <td>6820593.000000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>5762591.500000</td>\n",
       "      <td>6817945.000000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>5745142.500000</td>\n",
       "      <td>6805060.500000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>5757632.500000</td>\n",
       "      <td>6797427.000000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>5760349.500000</td>\n",
       "      <td>6812015.500000</td>\n",
       "      <td>00:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1554054/3279080324.py:7: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  res = self.func2(ys[0],torch.reshape(xs[0],(4,1)))\n",
      "/tmp/ipykernel_1554054/3279080324.py:9: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  res = res + self.func2(ys[i],torch.reshape(xs[i],(4,1)))\n",
      "/tmp/ipykernel_1554054/3279080324.py:10: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  res = res + self.func2(ys[6],torch.reshape(xs[6],(4,1)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 7239606.0.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 1 with valid_loss value: 7232471.0.\n",
      "Better model found at epoch 4 with valid_loss value: 7229250.0.\n",
      "Better model found at epoch 5 with valid_loss value: 7222905.5.\n",
      "Better model found at epoch 6 with valid_loss value: 7219139.0.\n",
      "Better model found at epoch 7 with valid_loss value: 7192810.0.\n",
      "Better model found at epoch 8 with valid_loss value: 7185082.0.\n",
      "Better model found at epoch 9 with valid_loss value: 7172340.5.\n",
      "Better model found at epoch 10 with valid_loss value: 7155692.5.\n",
      "Better model found at epoch 12 with valid_loss value: 7154866.5.\n",
      "Better model found at epoch 13 with valid_loss value: 7119400.5.\n",
      "Better model found at epoch 14 with valid_loss value: 7103815.5.\n",
      "Better model found at epoch 15 with valid_loss value: 7083582.5.\n",
      "Better model found at epoch 16 with valid_loss value: 7056889.0.\n",
      "Better model found at epoch 17 with valid_loss value: 7044088.0.\n",
      "Better model found at epoch 18 with valid_loss value: 7020479.0.\n",
      "Better model found at epoch 19 with valid_loss value: 7011983.0.\n",
      "Better model found at epoch 20 with valid_loss value: 6999818.0.\n",
      "Better model found at epoch 21 with valid_loss value: 6987280.5.\n",
      "Better model found at epoch 22 with valid_loss value: 6952589.5.\n",
      "Better model found at epoch 23 with valid_loss value: 6945623.5.\n",
      "Better model found at epoch 24 with valid_loss value: 6943307.0.\n",
      "Better model found at epoch 25 with valid_loss value: 6915576.0.\n",
      "Better model found at epoch 26 with valid_loss value: 6905672.0.\n",
      "Better model found at epoch 27 with valid_loss value: 6904635.0.\n",
      "Better model found at epoch 28 with valid_loss value: 6895794.0.\n",
      "Better model found at epoch 29 with valid_loss value: 6867685.5.\n",
      "Better model found at epoch 32 with valid_loss value: 6841894.5.\n",
      "Better model found at epoch 35 with valid_loss value: 6832430.5.\n",
      "Better model found at epoch 37 with valid_loss value: 6828253.0.\n",
      "Better model found at epoch 38 with valid_loss value: 6824210.5.\n",
      "Better model found at epoch 39 with valid_loss value: 6820759.0.\n",
      "Better model found at epoch 40 with valid_loss value: 6812674.0.\n",
      "Better model found at epoch 42 with valid_loss value: 6808751.5.\n",
      "Better model found at epoch 43 with valid_loss value: 6793389.5.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(50,lr_max=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = db.dataloaders(df,bs=4)\n",
    "learn.dls=dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1554054/3279080324.py:7: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  res = self.func2(ys[0],torch.reshape(xs[0],(4,1)))\n",
      "/tmp/ipykernel_1554054/3279080324.py:9: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  res = res + self.func2(ys[i],torch.reshape(xs[i],(4,1)))\n",
      "/tmp/ipykernel_1554054/3279080324.py:10: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  res = res + self.func2(ys[6],torch.reshape(xs[6],(4,1)))\n"
     ]
    }
   ],
   "source": [
    "preds,gt = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [7, 11]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmean_absolute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/sklearn/metrics/_regression.py:196\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean_absolute_error\u001b[39m(\n\u001b[1;32m    142\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    143\u001b[0m ):\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;124;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m    0.85...\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    200\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true), weights\u001b[38;5;241m=\u001b[39msample_weight, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/sklearn/metrics/_regression.py:100\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m        correct keyword.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    102\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/sklearn/utils/validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    385\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    390\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [7, 11]"
     ]
    }
   ],
   "source": [
    "mean_absolute_error(gt,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(gt,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sqrt(mean_squared_error(gt,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
